#!/usr/bin/env python3
"""
Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡ - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§Ø²Ù‡Ø§ÛŒ Û±ØŒ Û² Ùˆ Û³
"""

import sys
import json
import argparse
from pathlib import Path

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ PATH Ø¨Ø±Ø§ÛŒ import ØµØ­ÛŒØ­
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# ========== Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ÙØ§Ø² Û± ==========
try:
    from phase1.src.token_similarity_analyzer import TokenSimilarityAnalyzer
    PHASE1_OK = True
except ImportError as e:
    print("âš ï¸ ÙØ§Ø² Û± ÛŒØ§ÙØª Ù†Ø´Ø¯:", e)
    PHASE1_OK = False

# ========== Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ÙØ§Ø² Û² ==========
try:
    from phase2.src.analyzer import Phase2ASTSimilarity
    PHASE2_OK = True
except ImportError as e:
    print("âš ï¸ ÙØ§Ø² Û² ÛŒØ§ÙØª Ù†Ø´Ø¯:", e)
    PHASE2_OK = False

# ========== Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ÙØ§Ø² Û³ ==========
try:
    from phase3.analyzer.cfg_analyzer import Phase3CFGSimilarity
    PHASE3_OK = True
except ImportError as e:
    print("âš ï¸ ÙØ§Ø² Û³ ÛŒØ§ÙØª Ù†Ø´Ø¯:", e)
    PHASE3_OK = False


def read_file(path):
    with open(path, 'r', encoding='utf-8') as f:
        return f.read()


def main():
    parser = argparse.ArgumentParser(description='ØªØ´Ø®ÛŒØµ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ Ø¯Ø± Ú©Ø¯ - Ø³Ù‡ ÙØ§Ø² Ú©Ø§Ù…Ù„')
    parser.add_argument('file1', help='ÙØ§ÛŒÙ„ Ú©Ø¯ Ø§ÙˆÙ„')
    parser.add_argument('file2', help='ÙØ§ÛŒÙ„ Ú©Ø¯ Ø¯ÙˆÙ…')
    parser.add_argument('--lang', '-l', default='python', help='Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ (Ù¾ÛŒØ´ÙØ±Ø¶: python)')
    parser.add_argument('--output', '-o', default='final_report.json', help='ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ JSON')
    parser.add_argument('--verbose', '-v', action='store_true', help='Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª')
    args = parser.parse_args()

    code1 = read_file(args.code1)
    code2 = read_file(args.code2)

    print("=" * 70)
    print("ğŸ§ª  ØªØ­Ù„ÛŒÙ„ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ - Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù‡ ÙØ§Ø²")
    print("=" * 70)

    # ---------- ÙØ§Ø² Û± ----------
    phase1_res = None
    if PHASE1_OK:
        print("\n[ÙØ§Ø² Û±] ØªØ­Ù„ÛŒÙ„ ØªÙˆÚ©Ù† ...")
        analyzer1 = TokenSimilarityAnalyzer()
        phase1_res = analyzer1.calculate_similarity(code1, code2)
        print(f"   âœ… Ø´Ø¨Ø§Ù‡Øª ØªÙˆÚ©Ù†: {phase1_res.get('overall_similarity', 0):.2f}%")

    # ---------- ÙØ§Ø² Û² ----------
    phase2_res = None
    ast1_dict = None
    ast2_dict = None
    if PHASE2_OK:
        print("\n[ÙØ§Ø² Û²] ØªØ­Ù„ÛŒÙ„ Ø¯Ø±Ø®Øª Ù†Ø­ÙˆÛŒ (AST) ...")
        analyzer2 = Phase2ASTSimilarity()
        phase2_res = analyzer2.analyze_code_pair(code1, code2, args.lang, phase1_res)
        ast1_dict = phase2_res.get('ast1_dict')
        ast2_dict = phase2_res.get('ast2_dict')
        print(f"   âœ… Ø´Ø¨Ø§Ù‡Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ: {phase2_res.get('ast_similarity_score', 0):.2f}%")
        print(f"   ğŸ“Š Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ AST: {phase2_res.get('ast_statistics', {}).get('code1', {}).get('total_nodes', 0)} Ùˆ {phase2_res.get('ast_statistics', {}).get('code2', {}).get('total_nodes', 0)}")

    # ---------- ÙØ§Ø² Û³ ----------
    phase3_res = None
    if PHASE3_OK:
        print("\n[ÙØ§Ø² Û³] ØªØ­Ù„ÛŒÙ„ Ú¯Ø±Ø§Ù Ø¬Ø±ÛŒØ§Ù† Ú©Ù†ØªØ±Ù„ (CFG) ...")
        analyzer3 = Phase3CFGSimilarity()
        # Ø§Ø±Ø³Ø§Ù„ AST ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ phase2_res
        phase3_res = analyzer3.analyze_code_pair(
            code1, code2,
            phase1_results=phase1_res,
            phase2_results=phase2_res   # Ø­Ø§ÙˆÛŒ ast1_dict Ùˆ ast2_dict Ø§Ø³Øª
        )
        print(f"   âœ… Ø´Ø¨Ø§Ù‡Øª Ø±ÙØªØ§Ø±ÛŒ: {phase3_res.get('cfg_similarity_score', 0):.2f}%")
        if 'combined_similarity_score' in phase3_res:
            print(f"   ğŸ¯ Ù†Ù…Ø±Ù‡ ØªØ±Ú©ÛŒØ¨ÛŒ: {phase3_res['combined_similarity_score']:.2f}%")

    # ---------- ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ ----------
    final = {
        'code1': args.code1,
        'code2': args.code2,
        'language': args.lang,
        'phases_executed': {
            'phase1': phase1_res is not None,
            'phase2': phase2_res is not None,
            'phase3': phase3_res is not None
        }
    }

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù…Ø±Ø§Øª
    token_score = phase1_res.get('overall_similarity', 0) / 100 if phase1_res else 0.0
    ast_score = phase2_res.get('ast_similarity_score', 0) / 100 if phase2_res else 0.0
    cfg_score = phase3_res.get('cfg_similarity_score', 0) / 100 if phase3_res else 0.0

    weights = {'token': 0.2, 'ast': 0.3, 'cfg': 0.5}
    combined = (weights['token'] * token_score +
                weights['ast'] * ast_score +
                weights['cfg'] * cfg_score) * 100

    final['scores'] = {
        'token': token_score * 100,
        'ast': ast_score * 100,
        'cfg': cfg_score * 100,
        'combined': combined,
        'weights': weights
    }

    # ØªØ´Ø®ÛŒØµ Ø³Ø±Ù‚Øª
    threshold = 0.65
    is_plagiarism = combined >= (threshold * 100)
    final['verdict'] = {
        'threshold': threshold * 100,
        'is_plagiarism': is_plagiarism,
        'decision': 'PLAGIARISM_SUSPECTED' if is_plagiarism else 'CLEAN',
        'confidence': min(combined / 100, 1.0) * 100
    }

    # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(final, f, indent=2, ensure_ascii=False)

    print("\n" + "=" * 70)
    print("ğŸ“Š  Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
    print("=" * 70)
    print(f"ØªÙˆÚ©Ù†:     {final['scores']['token']:.2f}%")
    print(f"Ø³Ø§Ø®ØªØ§Ø±:   {final['scores']['ast']:.2f}%")
    print(f"Ø±ÙØªØ§Ø±:    {final['scores']['cfg']:.2f}%")
    print(f"ØªØ±Ú©ÛŒØ¨ÛŒ:   {final['scores']['combined']:.2f}%")
    print("-" * 70)
    print(f"ØªØ´Ø®ÛŒØµ:    {final['verdict']['decision']}")
    print(f"Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:  {final['verdict']['confidence']:.1f}%")
    print("=" * 70)
    print(f"\nğŸ“„ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¯Ø± {args.output} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")


if __name__ == '__main__':
    main()